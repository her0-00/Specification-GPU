import streamlit as st
import requests
import pandas as pd
import numpy as np
import plotly.express as px
import re
import seaborn as sns
import matplotlib.pyplot as plt


API_URL = "http://127.0.0.1:8000"

st.title("Apprentissaga automatique + prevision ( E-prod -CasQ'it)")

# --- Choix de la source

def convert_dataframe_types(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()

    # Convertir les colonnes num√©riques (m√™me si elles sont au format string)
    for col in df.columns:
        try:
            df[col] = pd.to_numeric(df[col])
        except (ValueError, TypeError):
            pass  # Ignore si la conversion √©choue

    
    return df
source = st.radio("Source de donn√©es", ["csv", "db"])
filename, table_name, username, password = None, None, None, None
df = None

if source == "csv":
    uploaded_file = st.file_uploader("Uploader un fichier CSV", type=["csv"])
    if uploaded_file is not None:
        files = {"file": (uploaded_file.name, uploaded_file.getvalue())}
        resp = requests.post(f"{API_URL}/upload_csv/", files=files)
        if resp.ok:
            filename = resp.json()["filename"]
            st.success(f"Fichier {filename} upload√© !")
            data_resp = requests.get(f"{API_URL}/get_csv_data/", params={"filename": filename})
            if data_resp.ok:
                data_json = data_resp.json()
                df = convert_dataframe_types(pd.DataFrame(data_json["data"], columns=data_json["columns"]))
          

                # Remplacer les None explicites par NaN (au cas o√π)
                df = df.where(pd.notnull(df), None)

                # Calcul du seuil : au moins 50 % de valeurs non manquantes
                seuil = len(df) * 0.5

                # Supprimer les colonnes avec plus de 50 % de valeurs manquantes
                df = df.dropna(axis=1, thresh=seuil)




                
            st.dataframe(df)
        else:
                st.error("Erreur de lecture des donn√©es")
    else:
            st.error("Erreur upload")

elif source == "db":
    st.header("Connexion √† la base PostgreSQL")
    username = st.text_input("Nom d'utilisateur DB")
    password = st.text_input("Mot de passe DB", type="password")
    if username and password:
        if st.button("Lister les tables"):
            req = {"username": username, "password": password, "query": ""}
            tables = requests.post(f"{API_URL}/db/list_tables/", json=req).json()
            st.session_state["db_tables"] = tables
        tables = st.session_state.get("db_tables", [])
        table_name = st.selectbox("Table", tables) if tables else None
        if table_name:
            sql = f"SELECT * FROM {table_name} limit 10"
            req = {"username": username, "password": password, "query": sql}
            data_resp = requests.post(f"{API_URL}/db/query/", json=req)
            if data_resp.ok:
                data_json = data_resp.json()
                df = convert_dataframe_types(pd.DataFrame(data_json["data"], columns=data_json["columns"]))
                 # Remplacer les None explicites par NaN (au cas o√π)
                df = df.where(pd.notnull(df), None)

                # Calcul du seuil : au moins 50 % de valeurs non manquantes
                seuil = len(df) * 0.5

                # Supprimer les colonnes avec plus de 50 % de valeurs manquantes
                df = df.dropna(axis=1, thresh=seuil)
                st.dataframe(df)

            else:
                st.error("Erreur de lecture des donn√©es")
if df is not None :
   
    df_clean = df.copy()
    df_clean = df_clean.replace([float('inf'), float('-inf')], pd.NA)
    df_clean = df_clean.dropna()



# --- Analyses si DataFrame charg√©
if df_clean is not None:
    # Statistiques
    with st.expander("Statistiques descriptives"):
        req = {
            "data": df_clean.to_numpy().tolist(),
            "columns": list(df_clean.columns)
        }
        desc = requests.post(f"{API_URL}/stats/describe/", json=req).json()
        st.write(pd.DataFrame(desc))

    with st.expander("Skewness & Kurtosis"):
        req = {
            "data": df_clean.to_numpy().tolist(),
            "columns": list(df_clean.columns)
        }
        response = requests.post(f"{API_URL}/stats/skew_kurtosis/", json=req)

        if response.ok:
            skew_kurt = response.json()
            st.json(skew_kurt)
        else:
            st.error(f"‚ùå Erreur API : {response.status_code} - {response.text}")

        

    # Outliers
    with st.expander("D√©tection d'outliers"):
        method = st.selectbox("M√©thode", ["zscore", "iqr"])
        threshold = st.slider("Seuil (z-score)", 2.0, 5.0, 3.0)
        req = {
            "data": df_clean.to_numpy().tolist(),
            "columns": list(df_clean.columns)
        }
        outliers = requests.post(
            f"{API_URL}/stats/outliers/",
            json=req,
            params={"method": method, "threshold": threshold}
        ).json()
        st.write(outliers)

    # Visualisation

st.header("Visualisation")



if df is not None:
    num_cols = df.select_dtypes(include=np.number).columns.tolist()
    req = {
        "data": df_clean.to_numpy().tolist(),
        "columns": list(df_clean.columns)
    }
   
    # Exemple : s√©lection de la colonne √† visualiser
    col_name = st.selectbox("üìå S√©lectionnez une colonne √† visualiser", df_clean.columns)


    # Appel √† l'API
    response = requests.post(
        f"{API_URL}/visualization/histogram/",
        json=req,
        params={"col_name": col_name}
    )

    # Affichage du graphique
    if response.ok:
        hist_response = response.json()

        if pd.api.types.is_numeric_dtype(df_clean[col_name]):
            # Histogramme pour donn√©es quantitatives
            hist_df = pd.DataFrame({
                "count": hist_response["hist"],
                "bin_start": hist_response["bin_edges"][:-1],
                "bin_end": hist_response["bin_edges"][1:]
            })
            st.subheader("üìä Histogramme")
            st.plotly_chart(
                px.bar(hist_df, x="bin_start", y="count", labels={"bin_start": col_name}),
                use_container_width=True
            )
        else:
            # Diagramme en barres pour donn√©es qualitatives
            hist_df = pd.DataFrame({
                "modalities": hist_response["modalities"],
                "frequencies": hist_response["frequencies"]
            })
            st.subheader("üìä Diagramme en barres")
            st.plotly_chart(
                px.bar(hist_df, x="modalities", y="frequencies", labels={"modalities": col_name}),
                use_container_width=True
            )
    else:
        st.error(f"‚ùå Erreur lors de la r√©cup√©ration des donn√©es : {response.text}")

        # Boxplot
        col_num = st.selectbox("Colonne num√©rique", num_cols, key="hist_box_col")
        box_response = requests.post(
            f"{API_URL}/visualization/boxplot/", json=req,
            params={"col_nums": col_num}
        ).json()
        box_df = pd.DataFrame({
            "stat": ["min", "q1", "median", "q3", "max"],
            "value": [box_response["min"], box_response["q1"], box_response["median"], box_response["q3"], box_response["max"]]
        })
        st.subheader("Boxplot")
        st.plotly_chart(px.box(df, y=col_num), use_container_width=True)

    # Scatter plot
    st.subheader("Nuage de points")
    col_x = st.selectbox("Axe X", num_cols, key="scatter_x")
    col_y = st.selectbox("Axe Y", num_cols, key="scatter_y")
    if col_x and col_y:
        scatter_response = requests.post(
            f"{API_URL}/visualization/scatter/", json=req,
            params={"x": col_x, "y": col_y}
        ).json()
        scatter_df = pd.DataFrame({
            col_x: scatter_response["x"],
            col_y: scatter_response["y"]
        })
        st.plotly_chart(px.scatter(scatter_df, x=col_x, y=col_y), use_container_width=True)

#--ML--



    st.header("üß† Machine Learning non supervis√©")



    st.subheader("‚öôÔ∏è Entra√Ænement d‚Äôun mod√®le")

    features = st.multiselect("üî¢ Variables explicatives (features)", list(df_clean.columns), key="train_features")
    target = st.selectbox("üéØ Variable cible", list(df_clean.columns), key="train_target")
    # Remplacer les valeurs nulles dans la colonne cible par "Non renseign√©"
    df_clean[target] = df_clean[target].fillna("Non renseign√©")
    df_clean[target].where(pd.notnull(df_clean[target]), None)
    df_clean[target] = df_clean[target].fillna("Non renseign√©")
    def normaliser_statut(texte):
        if pd.isnull(texte):
            return texte
        # Remplacer les variantes de "accept√©"
        texte = re.sub(r"\b(accepte[e√©]?|accept√©[e]?|accepte|accepte√©|accepteee|accepte√©|acepte|acpt√©)\b", "Accept√©e", str(texte), flags=re.IGNORECASE)
        # Remplacer les variantes de "refus√©"
        texte = re.sub(r"\b(refuse[e√©]?|refus√©[e]?|refuse|refusee|refuse√©|refus)\b", "Refus√©e", str(texte), flags=re.IGNORECASE)
        return texte


    df_clean[target]  = df_clean[target].apply(normaliser_statut)

    model_type = st.selectbox("üß™ Mod√®le", [
        "RandomForest", "LogisticRegression", "SVM", "GradientBoosting", "MLP"
    ], key="train_model")

    if st.button("üöÄ Entra√Æner le mod√®le") and features and target:
        df_ss = df_clean[features + [target]]  # Sous-ensemble des colonnes s√©lectionn√©es
        
        st.write(f"üìâ Nombre de lignes apr√®s nettoyage : {len(df_ss)}")

        if df_ss.empty:
            st.warning("‚ö†Ô∏è Aucune donn√©e disponible apr√®s nettoyage. Veuillez v√©rifier les valeurs manquantes ou infinies dans votre fichier.")
        else:

            req = {
                "data": df_ss.to_numpy().tolist(),
                "columns": list(df_ss.columns),
                "target_column": target,
                "model_type": model_type,
                "test_size": 0.2,
                "random_state": 42,
                "selected_features": features,
                "session_id": "session1"
            }

            with st.spinner("Entra√Ænement en cours..."):
                ml_resp = requests.post(f"{API_URL}/ml/train/", json=req)

            if ml_resp.ok:
                ml_res = ml_resp.json()
                st.success("‚úÖ Mod√®le entra√Æn√© avec succ√®s !")
                st.write("üéØ **Accuracy** :", ml_res["accuracy"])
                st.text("üìä Rapport de classification :")
                st.code(ml_res["report"])
                # Conversion en matrice numpy
                confusion_matrix = np.array([
                    [ ml_res["confusion_matrix"][0][0],  ml_res["confusion_matrix"][0][1],  ml_res["confusion_matrix"][0][2]],
                    [ ml_res["confusion_matrix"][1][0],  ml_res["confusion_matrix"][1][1],  ml_res["confusion_matrix"][1][2]],
                    [ ml_res["confusion_matrix"][2][0],  ml_res["confusion_matrix"][2][1],  ml_res["confusion_matrix"][2][2]]
                ])

                # √âtiquettes des classes
                class_labels = ["Classe 0", "Classe 1", "Classe 2"]

                # Affichage de la heatmap
                fig, ax = plt.subplots()
                sns.heatmap(confusion_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=class_labels, yticklabels=class_labels, ax=ax)
                ax.set_xlabel("Pr√©dit")
                ax.set_ylabel("R√©el")
                ax.set_title("üß© Matrice de confusion")

                st.pyplot(fig)

                st.session_state["model_path"] = ml_res["model_path"]
            else:
                st.error(f"‚ùå Erreur dans l'entra√Ænement : {ml_resp.text}")




    st.subheader("üìä Comparaison de plusieurs mod√®les")

    compare_features = st.multiselect("Variables explicatives (features)", list(df_clean.columns), key="compare_features")
    compare_target = st.selectbox("Variable cible", list(df_clean.columns), key="compare_target")
    model_types = st.multiselect("Mod√®les √† comparer", [
        "RandomForest", "LogisticRegression", "SVM", "GradientBoosting", "MLP"
    ], default=["RandomForest", "LogisticRegression"], key="compare_models")

    if st.button("Comparer les mod√®les") and compare_features and compare_target and model_types:
        req = {
            "data": df_clean.to_numpy().tolist(),
            "columns": list(df_clean.columns),
            "target_column": compare_target,
            "test_size": 0.2,
            "random_state": 42,
            "session_id": "session1",
            "selected_features": compare_features,
            "model_types": model_types
        }

        compare_resp = requests.post(f"{API_URL}/ml/compare/", json=req)
        if compare_resp.ok:
            results = compare_resp.json()
            for model_name, metrics in results.items():
                st.subheader(f"üß† R√©sultats pour {model_name}")
                if "error" in metrics:
                    st.error(f"Erreur : {metrics['error']}")
                else:
                    st.write("üéØ Accuracy :", metrics["accuracy"])
                    st.text("üìä Rapport de classification :")
                    st.code(metrics["report"])
                    st.write("üß© Matrice de confusion :", metrics["confusion_matrix"])
        else:
            st.error(f"‚ùå Erreur lors de la comparaison : {compare_resp.text}")

    st.subheader("üîÆ Pr√©diction sur les 5 premi√®res lignes")

    if  features is not None :#"model_path" in st.session_state and features:
        if st.button("Prediction"):
            pred_data = df_clean[features].head(5).values.tolist()
            pred_req = {
                "data": pred_data,
                "columns": features,
                "session_id": "session1"
            } 
            pred_resp = requests.post(f"{API_URL}/ml/predict/", json=pred_req)
            if pred_resp.ok:
                st.write("üìà Pr√©dictions :", pred_resp.json()["predictions"])
            else:
                st.error(f"‚ùå Erreur lors de la pr√©diction : {pred_resp.text}")


        # Clustering


    st.header("üîç Clustering non supervis√© (KMeans)")

    if df is not None:
        numeric_cols = df.select_dtypes(include=["number"]).columns.tolist()
        features = st.multiselect("S√©lectionnez les variables num√©riques √† utiliser", numeric_cols)
        n_clusters = st.slider("Nombre de clusters", min_value=2, max_value=10, value=3)

        if st.button("Lancer le clustering") and features:
            params = {
                "source": "local",
                "features": features,
                "n_clusters": n_clusters
            }

            try:
                response = requests.post(f"{API_URL}/clustering/kmeans/", params=params)
                if response.ok:
                    result = response.json()
                    df["cluster"] = result["clusters"]
                    st.success("‚úÖ Clustering effectu√© avec succ√®s !")
                    st.write("üìç Centres des clusters :", result["centers"])

                    if len(features) == 2:
                        fig = px.scatter(
                            df,
                            x=features[0],
                            y=features[1],
                            color=df["cluster"].astype(str),
                            title="Visualisation des clusters",
                            labels={"color": "Cluster"}
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.info("S√©lectionnez exactement 2 variables pour afficher un graphique de dispersion.")
                else:
                    st.error(f"Erreur lors du clustering : {response.text}")
            except Exception as e:
                st.error(f"Erreur de communication avec l'API : {str(e)}")
